<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Photographie Computationnelle</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">La Photographie computationnelle</a></h1>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

						<!-- Menu -->
						<nav id="menu">
							<div class="inner">
								<h2>Menu</h2>
								<ul class="links">
									<li><a href="index.html">Accueil</a></li>
									<li><a href="generic.html"> Définiton </a></li>
									<li><a href="etatdelart.html"> Etat de l'art </a></li>
									<li><a href="actu.html">Actualités</a></li>
								</ul>
								<a href="#" class="close">Close</a>
							</div>
						</nav>

				<!-- Wrapper -->
					<section id="wrapper">
						<header>
							<div class="inner">
								<h2>Mode Portrait</h2>
								<p>Ce mode permet de détourer des sujets et flouter l'arrière plan pour obtenir un effet de faible 
									profondeur de champ très apprécié dans la photographie de portrait</p>
							</div>
						</header>

						<!-- Content -->
							<div class="wrapper">
								<div class="inner">

									<h3 class="major">Principe</h3>
									<p>
										Le materiel photographique des smartphones ne permet pas de réaliser naturellement du flou d'arrière plan. 
										En effet le flou s'obtient avec des objectifs de longue focale, de grande ouverture et des grands capteurs. 
										Sur les téléphone on ne peut avoir des objectifs avec de longue focale, ni de grands capteurs. Il faut donc créer le flou 
										d'une atre manière. Plusieurs méthodes logicielles permettent de réaliser ce flou. Elles s'appuient en grande majorité sur
										le calcul et la détéction de la profondeur de la scène. Ce calcul de profondeur s'appuie dans la majorité des cas sur un système 
										de stéréo-vision qui compare le décalage des points entre deux images prises de deux points de vues sensiblements différents. 

									</p>


								

									<h3 class="major">Techniques</h3>

									<p>
										Multi caméras Depth Map:
									</p>

									<p> 
										Les appareils dotés de plusieurs caméras comme les smartphones récents peuvent utiliser deux clichés de la même scène pris avec des angles de vue légèrement 
										différents pour calculer la profondeur de la scène en chaque point. Cette profondeur se retrouve grâce à l'amplitude de l'écart de postion entre un même point dans les 
										deux images. C'est le même fonctionnement que la vision humaine. Plus un point est à des positions éloignées sur les deux images, plus il est proche des capteurs. La 
										carte de la profondeur (Depth map) peut ensuite être utilisée pour appliquer des traitements différents aux différents plans de l'image, le plus classique étant de flouter 
										les éléments des plans secondaires pour reproduire le "bokeh" ou flou d'arrière plan des appareils photo reflex.
									</p>


										<div class="fig">
											<figure>
												
												<img src="images/portrait_mode_aplle.png" alt="" width="400"  >
												<figcaption><i><a href="https://developer.apple.com/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth" >Apple developer : Capturing photos with depth
												</a></i></figcaption>
											</figure>
											</div>

										<p style="margin-top: 50px"> 
										
											Les deux images sont souvent prétraitées afin de retrouver plus facilement les points de correspondances pour calculer des disparités entre des 
											pixels de la même ligne sur les deux images. Toute la difficulté est alors d'avoir un algorithme de mise en correspondance efficace pour calculer 
											les disparités (décalage spatial d'un point de la scène entre les deux images). En effet entre les deux projections formées par les deux images, il 
											n'y a pas forcément la même intenisté lumineuse, les mêmes points visibles en fonction des angles de vue, et du bruit qui vient s'ajouter à l'information.
											Le prétraitement prenant en compte la disposition géométrique des capteurs premet une rectification qui va restreindre la recheche à des lignes de pixels appelés "épipoles".


										</p>
										
									

									<p>
										Dual-pixel:
									</p>
									<p>
										Dual-pixel est une technologie développée par Google pour ses téléphones Pixels qui ne disposaient à l'orogine que d'une caméra. Avec une 
										seule caméra, il est matériellement impossible d'utiliser l'effet de stéréo-vision pour calculer la profondeur de champs. Pour 
										faire cela, Google sépare chaque pixel en deux. De cette manière on peut obtenir deux vues légèrement différentes de la scène 
										avec un seul appareil photo comme s'il y en avait virtellement deux. Comme en stéréo-vision, la profondeur de champ se retrouve grâce au parallaxe, c'est à 
										dire le mouvement des points entre les images. Cependant cette méthode de caméras virtuelles ne fonctionne pas pour estimer la profondeur d'objets lointains car 
										la distance séparant les deux appareils virtuels est très faible (inférieure au millimètre).
									</p>

									<p>
										Les derniers téléphones de la marque étant équipé de plusieurs caméras, ils combinent la technologie classique de stéréo-vision par plusieurs capteurs physique avec cette méthode. 
										En effet la méthode "Dual-pixel" est complémentaire et permet d'avoir des informations sur la profondeurs de points qui seraient visibles sur une des images prise par un des appareils 
										mais invisible sur l'autre en raison du décalage plus important de l'angle de vue. C'est donc une méthode qui permet d'affiner la segmentation spatiale de l'image.

									</p>



									
									<div class="fig">
									<figure>
										<img src="images/Dual-pixel.png" alt="" width="400"  >
										
										</a></i></figcaption>
									</figure>
									</div>

									<div class="fig">
										<figure>
											
											<img src="images/Dual-pixel.gif" alt="" width="500"  >
											<figcaption><i><a href="https://www.googblogs.com/improvements-to-portrait-mode-on-the-google-pixel-4-and-pixel-4-xl/" >Google AI Blog : Dual-Pixel
											</a></i></figcaption>
										</figure>
										</div>

									


									<p style="margin-top: 50px" >
									</p>

									<p>
										Autres techniques:
									</p>

									<p>
										D'autres techniques comme la segmentation par intelligence artificielle permettent d'obtenir cet effet de flou artificiel. Par exemple les derniers smartphones d'Apple sont équipés d'un LiDAR. Le LiDAR utilise
										des émissions de lumière invisible pour calculer des distances par télémétrie. La distance est calculée comme pour un radar ou un sonar, c'est 
										à dire en mesurant le délai entre l'émission d'une impulsion et la détéction d'une implusion réfléchie. La miniaturisation de cette technologie sur 
										les smartphones peremt d'obtenir des cartes de profondeur de scène plus détaillées et de capturer des images 3D de certains objets. La photographie computationnelle 
										peut donc aussi s'appuyer sur des innovations matérielles.

										<div class="fig">
											<figure>
												
												<img src="images/iphone13.jpg" alt="" width="200"  >
												<figcaption><i><a href="https://www.apple.com/fr/newsroom/2021/09/apple-unveils-iphone-13-pro-and-iphone-13-pro-max-more-pro-than-ever-before/" >Apple : iPhone 13 avec ses 3 caméras et son LiDAR
												</a></i></figcaption>
											</figure>
											</div>

									</p>

									


									<h3 class="major" style="margin-top: 50px">Exemples</h3>
									<p style="margin-top: 10px"> 

										<div class="fig">
											<figure>
												
												<img src="images/portrait_mode_google.jpg" alt="" width="300"  >
												<figcaption><i><a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html" >Google AI Blog : Portrait mode on the Pixel 2 and Pixel 2 XL smartphones
												</a></i></figcaption>
											</figure>
											</div>
										
									</p>
									

								</div>
							</div>

					</section>

				<!-- Footer -->
					<section id="footer">
						<div class="inner">
							<h2 class="major">Sources</h2>
							<p>

								<ul class="links">
									<li><a  href="https://doi.org/10.1007/978-3-319-23192-1_17">Liu, Dongwei, Radu Nicolescu, et Reinhard Klette. « Bokeh Effects Based on Stereo Vision », 2015.</a></li>
									<li><a href="http://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Google AI Blog. « Portrait Mode on the Pixel 2 and Pixel 2 XL Smartphones ». Consulté le 03 mars 2022.</a></li>
									<li><a href="https://www.googblogs.com/improvements-to-portrait-mode-on-the-google-pixel-4-and-pixel-4-xl/">AI, Google. « Improvements to Portrait Mode on the Google Pixel 4 and Pixel 4 XL | Googblogs.Com ». Consulté le 03 mars 2022.</a></li>
								</ul>
								
								
								
								

								 


							</p>
							
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>